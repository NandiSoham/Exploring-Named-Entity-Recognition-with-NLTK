{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Named Entity Recognition with NLTK: A Beginner's Guide.\n",
    "\n",
    "In the vast landscape of information available online, it can be challenging to extract meaningful insights from articles. That's where our project steps in, employing a clever tool called Named Entity Recognition (NER). Think of NER as a friendly guide that helps computers recognize and categorize important details like names of people, places, and organizations within a sea of words.\n",
    "\n",
    "Our project specifically focuses on reading news articles. Using the Natural Language Toolkit (NLTK), our system breaks down sentences, identifies the roles of words (like names or locations), and highlights significant information. It's like having a language wizard that points out crucial details, making it easier to understand the main points of an article. This not only aids in digesting information quickly but also helps readers, researchers, and analysts make more informed decisions.\n",
    "\n",
    "In essence, our project is all about simplifying the complexity of text. By applying NER to news articles, we're providing a tool that enhances comprehension, making it accessible for anyone navigating through a barrage of information. Whether you're a student, researcher, or someone curious about current events, our project strives to make the wealth of online knowledge more understandable and user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Importing Necessary Libraries and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement. Barack Obama is the husband of Michelle Obama.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "#--- Read in text file(text.txt) ----\n",
    "filepath = \"textfile.txt\"\n",
    "\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    my_text = file.read()\n",
    "\n",
    "my_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Tokenizing the Sentence.\n",
    " Now, we need to split each word into a separate element. By doing this, we enable our system to analyze and understand the structure of the text more effectively. \n",
    "\n",
    " Tokenize a given sentence(my_text). Store the tokenized words in the variable tokenized_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nandi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WASHINGTON',\n",
       " '--',\n",
       " 'In',\n",
       " 'the',\n",
       " 'wake',\n",
       " 'of',\n",
       " 'a',\n",
       " 'string',\n",
       " 'of',\n",
       " 'abuses',\n",
       " 'by',\n",
       " 'New',\n",
       " 'York',\n",
       " 'police',\n",
       " 'officers',\n",
       " 'in',\n",
       " 'the',\n",
       " '1990s',\n",
       " ',',\n",
       " 'Loretta',\n",
       " 'E.',\n",
       " 'Lynch',\n",
       " ',',\n",
       " 'the',\n",
       " 'top',\n",
       " 'federal',\n",
       " 'prosecutor',\n",
       " 'in',\n",
       " 'Brooklyn',\n",
       " ',',\n",
       " 'spoke',\n",
       " 'forcefully',\n",
       " 'about',\n",
       " 'the',\n",
       " 'pain',\n",
       " 'of',\n",
       " 'a',\n",
       " 'broken',\n",
       " 'trust',\n",
       " 'that',\n",
       " 'African-Americans',\n",
       " 'felt',\n",
       " 'and',\n",
       " 'said',\n",
       " 'the',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'repairing',\n",
       " 'generations',\n",
       " 'of',\n",
       " 'miscommunication',\n",
       " 'and',\n",
       " 'mistrust',\n",
       " 'fell',\n",
       " 'to',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " '.',\n",
       " 'Barack',\n",
       " 'Obama',\n",
       " 'is',\n",
       " 'the',\n",
       " 'husband',\n",
       " 'of',\n",
       " 'Michelle',\n",
       " 'Obama',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_words = word_tokenize(my_text)\n",
    "\n",
    "tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
